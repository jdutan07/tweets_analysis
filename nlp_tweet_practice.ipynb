{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8963f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de19208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open json file\n",
    "with open('normal_tweets.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b751fd93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#normalize the json file\n",
    "df = pd.DataFrame.from_dict(pd.json_normalize(data), orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0d687",
   "metadata": {},
   "source": [
    "**Notice that the entire data is stored as one row and in one column. The code below addresses that.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff636c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate by rows\n",
    "df = df.explode('data', ignore_index=True)\n",
    "\n",
    "#expand columns to see full text\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5a561",
   "metadata": {},
   "source": [
    "**Data is successfully separated as individual columns, however, it is still stored as one row column. The code below addresses that.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd261bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data again\n",
    "df_data_normalize = json_normalize(df['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e97f9",
   "metadata": {},
   "source": [
    "**The code results in a DataFrame with 4 columns.**\n",
    "- edit_history_tweet_id\n",
    "- id\n",
    "- created_at\n",
    "- text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fcbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns for our analysis\n",
    "df = df_data_normalize.drop(columns=['edit_history_tweet_ids','id','created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979d37b",
   "metadata": {},
   "source": [
    "**code produces a new dataframe that separates each tweet in its own row. We have a total of 24 rows and 1 column named, \"text\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b591d1",
   "metadata": {},
   "source": [
    "## From this point onward I will be using basic Natural Language Processing to clean up the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963824ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccessary libraries\n",
    "import nltk\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43abbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some tweets have links. We only want the actual twitter text, so we \n",
    "#have to remove https links. \n",
    "df['text'] = [x.split('https')[0] for x in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bfd24",
   "metadata": {},
   "source": [
    "**Although we have removed \"https links\", the dataset is still marked with extra spaces and '\\n' text, indicating new lines in the tweet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2231a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check and remove all 'n' and extra space in texts\n",
    "def remove_newline(cell_value):\n",
    "    return cell_value.replace(\"\\n\", \" \")\n",
    "\n",
    "#apply the remove_newline function to each cell in the specified column\n",
    "df['text'] = df['text'].apply(remove_newline)\n",
    "\n",
    "#convert all text to lower case to maintain standard in text standardization\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add33ab9",
   "metadata": {},
   "source": [
    "**Texts are all in lowercase, but our data must only contain Spanish tweets. We must remove tweets that are not detected in the Spanish language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ecac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to detect text language\n",
    "def detect_my(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except: return 'unknown'\n",
    "    \n",
    "#we are creating a new column that will have values classifying the language each tweet is in \n",
    "df['language'] = df['text'].apply(detect_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9d7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we want to query spanish tweets\n",
    "#this will effectively remove any tweet not in Spanish\n",
    "new_df = df.query(\"language =='es'\")['text']\n",
    "\n",
    "#convert the results into a dataframe\n",
    "new_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc738e",
   "metadata": {},
   "source": [
    "**Our data now contains only Spanish tweets. Still, the data needs to be cleaned further for it to be ready for sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db9569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import proper libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5b4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before removing filler words in our tweets, we need to tokenize it\n",
    "new_df['text'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "#set up stopwords to spanish\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "#apply to data\n",
    "new_df = new_df['text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#convert resuls to dataframe\n",
    "new_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69349a1b",
   "metadata": {},
   "source": [
    "**The final data shows each tweet in its own row, fully tokenized, and with no filler words**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372db78",
   "metadata": {},
   "source": [
    "**For privacy reasons and to stay compliant with Twitter's Policy, I do not think I can show the final outcome. Furthermore, at this point, I did not have enough to time to finish the overall analysis as I had to hand in my capstone. I was also not too positive if my approach to conduct sentiment analysis was right. However, given the research papers I have read on this topic, it is possible.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
